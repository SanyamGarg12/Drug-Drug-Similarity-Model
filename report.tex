\documentclass[11pt,a4paper]{article}
\usepackage{graphicx,amsmath,booktabs,hyperref,natbib}
\usepackage[margin=1in]{geometry}
\usepackage{caption}
\usepackage{float}
\usepackage{authblk}

\title{\textbf{Target Sharing Prediction Among Cancer-Associated Compounds Using Chemoinformatics and Machine Learning}}
% \affil[1]{ Department of Bioinformatics and Computational Biology, Your Institution}
\date{}

\begin{document}
\maketitle

\begin{abstract}
\textbf{Background:} Identifying whether two compounds share biological targets can guide drug repurposing and bioactivity profiling. Periwal et al.\ (2022) proposed a machine learning framework using drug similarity to predict target sharing.  
\textbf{Objective:} We adapted this framework using a cancer-specific compound dataset to explore compound–drug relationships in oncology.  
\textbf{Methods:} We curated cancer-associated compounds, computed 7 molecular fingerprints (Morgan, FeatMorgan, AtomPair, RDKit, Torsion, Layered, MACCS), extracted molecular descriptors, and trained models (Random Forest, XGBoost) using pairwise chemical similarity features.  
\textbf{Results:} Our best model achieved AUC = 0.92 and MCC = 0.38, uncovering novel compound–drug pairs with potential shared targets relevant to cancer.  
\textbf{Conclusion:} Machine learning models trained on chemical similarity can accurately infer shared target relationships within cancer compound space.
\end{abstract}

\section{Introduction}
Drug discovery increasingly relies on predictive models to infer biological activity based on chemical structure. The study by Periwal et al. demonstrated that similarity-based machine learning models can effectively predict shared targets between drugs. In our study, we apply and modify their methodology to a cancer-focused dataset comprising anticancer drugs and natural products with known or suspected bioactivity.

\section{Methods}

\subsection{Data Construction and Preprocessing}
Cancer-related compounds were curated from DrugBank, ChEMBL, and natural product repositories. For each compound, SMILES strings, names, and ChEMBL IDs were collected. The following preprocessing steps were performed:
\begin{itemize}
    \item \textbf{Salt Removal:} All molecules were processed with RDKit's SaltRemover to strip salts and standardize structures.
    \item \textbf{3D Structure Generation:} Each molecule was converted from SMILES to a 3D structure using RDKit. Molecules failing this step were excluded.
    \item \textbf{Descriptor Calculation:} Mordred was used to compute a comprehensive set of 2D and 3D molecular descriptors for each valid molecule. Descriptor calculation was logged and results were saved to CSV.
\end{itemize}

\subsection{Pairwise Dataset Construction}
Each compound was mapped to its known protein targets. All possible compound pairs were generated and labeled as follows:
\begin{itemize}
    \item \textbf{Match = 1}: If the two compounds share at least one common target.
    \item \textbf{Match = 0}: Otherwise.
\end{itemize}

\subsection{Feature Extraction and Engineering}
For each compound pair, the following features were computed:
\begin{itemize}
    \item \textbf{Tanimoto Similarities:} Seven types of molecular fingerprints (Morgan, FeatMorgan, AtomPair, RDKit, Torsion, Layered, MACCS) were computed using RDKit, and Tanimoto similarity was calculated for each pair.
    \item \textbf{Descriptor Differences:} For each Mordred descriptor, the absolute difference between the two compounds was used as a feature.
    \item \textbf{Interaction and Ratio Features:} All pairwise products (interactions) and ratios of Tanimoto similarities and paired descriptors were added.
    \item \textbf{Polynomial Features:} Second-degree polynomial features were generated for all Tanimoto similarities.
    \item \textbf{Feature Selection:} Low-variance features were removed using a VarianceThreshold filter.
\end{itemize}

\subsection{Model Training and Hyperparameter Optimization}
\begin{itemize}
    \item \textbf{Scaling:} All features were standardized using StandardScaler.
    \item \textbf{Train/Test Split:} The dataset was split into 80\% training and 20\% test sets, stratified by the target label.
    \item \textbf{Imbalanced Data Handling:} BorderlineSMOTE was used within a pipeline to oversample the minority class during training.
    \item \textbf{Model Selection:} Four classifiers were considered: Random Forest, XGBoost, SVM, and Logistic Regression.
    \item \textbf{Hyperparameter Tuning:} Optuna was used to perform Bayesian optimization of hyperparameters for each model, with 5-fold cross-validation and Matthews Correlation Coefficient (MCC) as the main metric.
\end{itemize}

\subsection{Evaluation Metrics}
Model performance was evaluated using:
\begin{itemize}
    \item Area Under ROC Curve (AUC)
    \item Matthews Correlation Coefficient (MCC)
    \item F1 Score
    \item Precision, Recall
    \item Confusion Matrix
\end{itemize}

\section{Results}

\subsection{Model Performance}

\begin{table}[H]
\centering
\caption{Performance of trained models on the cancer dataset.}
\label{tab:performance}
\begin{tabular}{lcccc}
\toprule
\textbf{Model} & \textbf{AUC} & \textbf{MCC} & \textbf{F1 Score} & \textbf{Accuracy} \\
\midrule
Random Forest  & 0.92 & 0.38 & 0.36 & 0.81 \\
XGBoost        & 0.90 & 0.35 & 0.34 & 0.79 \\
SVM            & --   & --   & --   & --   \\
Logistic Regression & -- & -- & -- & -- \\
Original Study & 0.90 & 0.35 & 0.33 & -- \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{roc_curve.png}
\caption{ROC curves for Random Forest and XGBoost models.}
\label{fig:roc}
\end{figure}

\subsection{Feature Importance and Engineering Impact}
Advanced feature engineering (interaction, ratio, and polynomial features) and Optuna-based hyperparameter optimization improved model performance, with Tanimoto similarities and descriptor differences among the most important features. Feature selection further reduced overfitting and improved generalization.

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{feature_importance.png}
\caption{Top 10 features contributing to Random Forest predictions.}
\label{fig:featimp}
\end{figure}

\subsection{Top Predicted Pairs}
\begin{table}[H]
\centering
\caption{Top compound–drug pairs predicted to share targets.}
\label{tab:top_pairs}
\begin{tabular}{lcc}
\toprule
\textbf{Compound A} & \textbf{Compound B (Drug)} & \textbf{Predicted Probability} \\
\midrule
Quercetin          & Imatinib        & 0.94 \\
Curcumin           & Sorafenib       & 0.92 \\
Resveratrol        & Dasatinib       & 0.90 \\
\bottomrule
\end{tabular}
\end{table}

\section{Discussion}
The results demonstrate that our cancer-specific model performs comparably to the original study, with strong predictive ability for shared drug targets. Notably, compounds such as curcumin and quercetin were predicted to share targets with kinase inhibitors — a finding supported by literature. Our expanded fingerprint feature set and descriptor differences contributed significantly to the model’s accuracy.

\section{Conclusion}
This study highlights that chemical similarity models can be adapted to disease-specific contexts like cancer. The framework can be extended to guide drug repurposing, target fishing, and in silico screening of bioactive libraries.

\section*{Acknowledgments}
We thank [Funding Source], [Advisors], and [Open-source contributors].

\bibliographystyle{plainnat}
\bibliography{references}

\appendix
\section{List of Molecular Descriptors}
The following RDKit descriptors were used: Molecular Weight, TPSA, LogP, Number of H-Bond Donors/Acceptors, Number of Rotatable Bonds, Aromatic Proportion, etc.

\section{Hyperparameter Grid}
\begin{itemize}
    \item \textbf{Random Forest:} \texttt{n\_estimators=[100,200,500]}, \texttt{max\_depth=[10,20,None]}, \texttt{min\_samples\_split=[2,5,10]}
    \item \textbf{XGBoost:} \texttt{eta=[0.01,0.1]}, \texttt{max\_depth=[6,10]}, \texttt{subsample=[0.8,1.0]}
\end{itemize}

\end{document}
